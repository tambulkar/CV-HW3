{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "convolutional-neural-networks",
      "graded_item_id": "OEpi5",
      "launcher_item_id": "jK9EQ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Starter.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ci7JfrFM3k4I",
        "colab_type": "text"
      },
      "source": [
        "# Import the Required Dependencies \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LD13_jJ3k4J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "3faf8c39-dad2-4479-88e3-a0f0d98bce76"
      },
      "source": [
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,Dropout\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "import keras \n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import cifar10\n",
        "from keras.regularizers import l1\n",
        "import os\n",
        "import time\n",
        "from time import time\n",
        "import pdb\n",
        "\n",
        "def plot_learningCurve(history,num_epoch):\n",
        "  # Plot training & validation accuracy values\n",
        "  epoch_range = np.arange(1,num_epoch+1)\n",
        "  plt.plot(epoch_range, history.history['acc'])\n",
        "  plt.plot(epoch_range, history.history['val_acc'])\n",
        "  plt.title('Model accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Val'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  # Plot training & validation loss values\n",
        "  plt.plot(epoch_range, history.history['loss'])\n",
        "  plt.plot(epoch_range, history.history['val_loss'])\n",
        "  plt.title('Model loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Val'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "save_dir='/model/resnet'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaqVr_T03XrW",
        "colab_type": "text"
      },
      "source": [
        "## Note on Conv2D\n",
        "\n",
        "In order to implement the convolutional layers, we use the Keras implementation of Conv2D. However, in all cases, you are required to use a specific kernel initializer so that the results are predictable ( random initialization of convolutional kernel would result in unpredictable ).\n",
        "\n",
        "As such, please use the following Conv2D: \n",
        "\n",
        "Conv2D(filters=f, kernel_size=(k, k), strides=(s, s), padding=pad_type, kernel_initializer=keras.initializers.glorot_uniform(seed=0))(X)\n",
        "\n",
        "In which f,k and s denote the size of filter,kernel and stride. Pad_type denoted the padding type which can be either \"same\" or \"valid\". "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eA51suF12fn",
        "colab_type": "text"
      },
      "source": [
        "##Implementing the Identity Block \n",
        "\n",
        "We discussed the identity block in the homework description. Here we provide the details of the components that you should use to implement it. \n",
        "\n",
        "The following represents the components: \n",
        "\n",
        "First component of main path: \n",
        "- The first CONV2D has $F_1$ filters of shape (1,1) and a stride of (1,1). Its padding is \"valid\". Use 0 as the seed for the random initialization. \n",
        "- The first BatchNorm is normalizing the channels axis. No particular argument needs to be passed.\n",
        "- Then apply the ReLU activation function. This has no hyperparameters. \n",
        "\n",
        "Second component of main path:\n",
        "- The second CONV2D has $F_2$ filters of shape $(f,f)$ and a stride of (1,1). Its padding is \"same\". Use 0 as the seed for the random initialization. \n",
        "- The second BatchNorm is normalizing the channels axis. No particular argument needs to be passed.\n",
        "- Then apply the ReLU activation function. This has no hyperparameters\n",
        "\n",
        "Third component of main path:\n",
        "- The third CONV2D has $F_3$ filters of shape (1,1) and a stride of (1,1). Its padding is \"valid\". Use 0 as the seed for the random initialization. \n",
        "- The third BatchNorm is normalizing the channels axis. No particular argument needs to be passed. \n",
        "- Then apply the ReLU activation function. This has no hyperparameters\n",
        "\n",
        "Final step: \n",
        "- The shortcut and the input are added together.\n",
        "- Then apply the ReLU activation function. This has no hyperparameters\n",
        "\n",
        "Useful links:\n",
        "\n",
        "- [Conv](https://keras.io/layers/convolutional/#conv2d)\n",
        "- [BatchNorm](https://keras.io/layers/normalization/#batchnormalization)\n",
        "- For the activation, use:  `Activation('relu')(X)`\n",
        "- [Addition](https://keras.io/layers/merge/#add)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJc-hKMN3k4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def identity_block(X, f, filters):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block as defined in Figure 4 of homework\n",
        "\n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path (e.g. [2,4,16])\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "\n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "\n",
        "    # Retrieve Filters\n",
        "    f1 = Conv2D(filters=filters[0], kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_initializer=keras.initializers.glorot_uniform(seed=0))\n",
        "    f2 = Conv2D(filters=filters[1], kernel_size=(f, f), strides=(1, 1), padding='same', kernel_initializer=keras.initializers.glorot_uniform(seed=0))\n",
        "    f3 = Conv2D(filters=filters[2], kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_initializer=keras.initializers.glorot_uniform(seed=0))\n",
        "   \n",
        "\n",
        "    # Save the input value. You'll need this later to add back to the main path.\n",
        "    original = X\n",
        "   \n",
        "\n",
        "    # First component of main path\n",
        "    X = f1(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "\n",
        "    # Second component of main path (≈3 lines)\n",
        "    X = f2(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "\n",
        "    # Third component of main path (≈2 lines)\n",
        "    X = f3(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    \n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X, original])\n",
        "    X = Activation('relu')(X)\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jSnfAHX8cUH",
        "colab_type": "text"
      },
      "source": [
        "##Testing the Identity Block\n",
        "\n",
        "Simply run the code in the following block and report the result that is generated in your homework report. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikDdEFha3k4R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "92b08488-11a4-4b38-b543-b444b594cbdb"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "with tf.Session() as test:\n",
        "    np.random.seed(1)\n",
        "    A_prev = tf.placeholder(\"float\", [4, 4, 4, 8])\n",
        "    X = np.random.randn(4,4,4,8)\n",
        "    A = identity_block(A_prev, f=2, filters=[2, 4, 8])\n",
        "    test.run(tf.global_variables_initializer())\n",
        "    res = test.run([A], feed_dict={A_prev: X})\n",
        "    print('Result = {}'.format(res[0][1][1][0]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "Result = [0.         0.         1.2319232  0.         0.04842055 0.39851195\n",
            " 1.703964   0.32821387]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQbD_ipW-06u",
        "colab_type": "text"
      },
      "source": [
        "##Implementing the Convolutional Block \n",
        "\n",
        "We discussed the convolutional block in the homework description. Here we provide the details of the components that you should use to implement it. \n",
        "\n",
        "The following represents the components: \n",
        "\n",
        "First component of main path:\n",
        "- The first CONV2D has $F_1$ filters of shape (1,1) and a stride of (s,s). Its padding is \"valid\". \n",
        "- The first BatchNorm is normalizing the channels axis. No particular argument needs to be passed.\n",
        "- Then apply the ReLU activation function. This has no hyperparameters. \n",
        "\n",
        "Second component of main path:\n",
        "- The second CONV2D has $F_2$ filters of (f,f) and a stride of (1,1). Its padding is \"same\".\n",
        "- The second BatchNorm is normalizing the channels axis. No particular argument needs to be passed.\n",
        "- Then apply the ReLU activation function. This has no hyperparameters. \n",
        "\n",
        "Third component of main path:\n",
        "- The third CONV2D has $F_3$ filters of (1,1) and a stride of (1,1). Its padding is \"valid\".\n",
        "- The third BatchNorm is normalizing the channels axis. No particular argument needs to be passed. Note that there is no ReLU activation function in this component. \n",
        "\n",
        "Shortcut path:\n",
        "- The CONV2D has $F_3$ filters of shape (1,1) and a stride of (s,s). Its padding is \"valid\".\n",
        "- The BatchNorm is normalizing the channels axis. BatchNorm is normalizing the channels axis. No particular argument needs to be passed\n",
        "\n",
        "Final step: \n",
        "- The shortcut and the main path values are added together.\n",
        "- Then apply the ReLU activation function. This has no name and no hyperparameters. \n",
        "\n",
        "Useful links:\n",
        "\n",
        "- [Conv](https://keras.io/layers/convolutional/#conv2d)\n",
        "- [BatchNorm](https://keras.io/layers/normalization/#batchnormalization)\n",
        "- For the activation, use:  `Activation('relu')(X)`\n",
        "- [Addition](https://keras.io/layers/merge/#add)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTTaFuRa3k4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convolutional_block(X, f, filters,stride=2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block as defined in Figure 5 of homework\n",
        "\n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path (e.g. [2,4,16])\n",
        "    stride -- Integer, specifying the stride to be used\n",
        "\n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "\n",
        "    # Retrieve Filters\n",
        "    f1 = Conv2D(filters=filters[0], kernel_size=(1, 1), strides=(stride, stride), padding='valid', kernel_initializer=keras.initializers.glorot_uniform(seed=0))\n",
        "    f2 = Conv2D(filters=filters[1], kernel_size=(f, f), strides=(1, 1), padding='same', kernel_initializer=keras.initializers.glorot_uniform(seed=0))\n",
        "    f3 = Conv2D(filters=filters[2], kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_initializer=keras.initializers.glorot_uniform(seed=0))\n",
        "    shortcut = Conv2D(filters=filters[2], kernel_size=(1, 1), strides=(stride, stride), padding='valid', kernel_initializer=keras.initializers.glorot_uniform(seed=0))\n",
        "\n",
        "    # Save the input value\n",
        "    original = X\n",
        "\n",
        "    # First component of main path \n",
        "    X = f1(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Second component of main path (≈3 lines)\n",
        "    X = f2(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path (≈2 lines)\n",
        "    X = f3(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    \n",
        "    ##### SHORTCUT PATH #### (≈2 lines)\n",
        "    shortcut_X = shortcut(original)\n",
        "    shortcut_X = BatchNormalization()(shortcut_X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X, shortcut_X])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGITZoKUDBTs",
        "colab_type": "text"
      },
      "source": [
        "##Testing the Convolutional Block\n",
        "\n",
        "Simply run the code in the following block and report the result that is generated in your homework report. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQQAH8UM3k4X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5d952f13-86d9-4b91-a6b3-359f5610d4d4"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "with tf.Session() as test:\n",
        "    np.random.seed(1)\n",
        "    A_prev = tf.placeholder(\"float\", [4, 4, 4, 8])\n",
        "    X = np.random.randn(4,4,4,8)\n",
        "    A = convolutional_block(A_prev, f=2, filters=[2, 4, 8])\n",
        "    test.run(tf.global_variables_initializer())\n",
        "    res = test.run([A], feed_dict={A_prev: X})\n",
        "    print('Result = {}'.format(res[0][1][1][0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Result = [0.        1.3407363 1.4184607 0.        0.        2.2878466 0.8547394\n",
            " 0.5266884]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjLuQmAOFAgm",
        "colab_type": "text"
      },
      "source": [
        "##Implementing ResNet \n",
        "\n",
        "We discussed the ResNet architecture in the homework description ( see Figure 6 ). Here we provide further details you should use to implement it.\n",
        "The following represents ResNet components: \n",
        "\n",
        "- Zero-padding pads the input with a pad of (3,3)\n",
        "- Stage 1:\n",
        "    - The 2D Convolution has 64 filters of shape (7,7) and uses a stride of (2,2).\n",
        "    - BatchNorm is applied to the channels axis of the input.\n",
        "    - MaxPooling uses a (3,3) window and a (2,2) stride.\n",
        "- Stage 2:\n",
        "    - The convolutional block uses three set of filters of size [64,64,256], \"f\" is 3, \"s\" is 1.\n",
        "    - The 2 identity blocks use three set of filters of size [64,64,256], \"f\" is 3.\n",
        "- Stage 3:\n",
        "    - The convolutional block uses three set of filters of size [128,128,512], \"f\" is 3, \"s\" is 2.\n",
        "    - The 3 identity blocks use three set of filters of size [128,128,512], \"f\" is 3.\n",
        "- Stage 4:\n",
        "    - The convolutional block uses three set of filters of size [256, 256, 1024], \"f\" is 3, \"s\" is 2.\n",
        "    - The 5 identity blocks use three set of filters of size [256, 256, 1024], \"f\" is 3.\n",
        "- Stage 5:\n",
        "    - The convolutional block uses three set of filters of size [512, 512, 2048], \"f\" is 3, \"s\" is 2.\n",
        "    - The 2 identity blocks use three set of filters of size [256, 256, 2048], \"f\" is 3.\n",
        "- The 2D Average Pooling uses a window of shape (2,2).\n",
        "- The flatten doesn't have any hyperparameters.\n",
        "- The Fully Connected (Dense) layer reduces its input to the number of classes using a softmax activation.\n",
        "\n",
        "Useful links:\n",
        "\n",
        "- [Conv](https://keras.io/layers/convolutional/#conv2d)\n",
        "- [BatchNorm](https://keras.io/layers/normalization/#batchnormalization)\n",
        "- For the activation, use:  `Activation('relu')(X)`\n",
        "- [Addition](https://keras.io/layers/merge/#add)\n",
        "- [Average pooling](https://keras.io/layers/pooling/#averagepooling2d)\n",
        "- [Max pooling](https://keras.io/layers/pooling/#maxpooling2d)\n",
        "- [Zero padding](https://keras.io/layers/convolutional/#zeropadding2d)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHfdszLr3k4b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "2bd019aa-7524-4427-eb40-9fb42dfe7be9"
      },
      "source": [
        "def ResNet(input_shape=(32, 32, 3), classes=10):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D(padding=(3,3))(X_input)\n",
        "\n",
        "    # Stage 1\n",
        "    X = Conv2D(filters=64, kernel_size=(7,7), strides=(2,2), kernel_initializer=keras.initializers.glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D(pool_size=(3,3), strides=(2,2))(X)\n",
        "    \n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f=3, filters=[64,64,256], stride=1)\n",
        "    X = identity_block(X, f=3, filters=[64,64,256])\n",
        "    X = identity_block(X, f=3, filters=[64,64,256])\n",
        "\n",
        "    # pdb.set_trace()\n",
        "    # # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f=3, filters=[128,128,512], stride=2)\n",
        "    X = identity_block(X, f=3, filters=[128,128,512])\n",
        "    X = identity_block(X, f=3, filters=[128,128,512])\n",
        "    X = identity_block(X, f=3, filters=[128,128,512])\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f=3, filters=[256,256,1024], stride=2)\n",
        "    X = identity_block(X, f=3, filters=[256,256,1024])\n",
        "    X = identity_block(X, f=3, filters=[256,256,1024])\n",
        "    X = identity_block(X, f=3, filters=[256,256,1024])\n",
        "    X = identity_block(X, f=3, filters=[256,256,1024])\n",
        "    X = identity_block(X, f=3, filters=[256,256,1024])\n",
        "    # pdb.set_trace()\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f=3, filters=[512,512,2048], stride=2)\n",
        "    X = identity_block(X, f=3, filters=[256,256,2048])\n",
        "    X = identity_block(X, f=3, filters=[256,256,2048])\n",
        "    \n",
        "    # AVGPOOL (≈1 line)\n",
        "    X = AveragePooling2D(pool_size=(2,2), padding='same')(X)\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', kernel_initializer=keras.initializers.glorot_uniform(seed=0))(X)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs=X_input, outputs=X, name='ResNet')\n",
        "\n",
        "    return model\n",
        "\n",
        "model = ResNet(input_shape=(32, 32, 3), classes=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIlOuEUT9P7z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "563ac1c8-e8a0-4683-9ea4-22726f722088"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 38, 38, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   9472        zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   256         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 7, 7, 64)     0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 7, 7, 64)     4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 7, 7, 64)     256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 7, 7, 64)     0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 7, 7, 64)     36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 7, 7, 64)     256         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 7, 7, 64)     0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 7, 7, 256)    16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 7, 7, 256)    16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 7, 7, 256)    1024        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 7, 7, 256)    1024        conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 7, 7, 256)    0           batch_normalization_8[0][0]      \n",
            "                                                                 batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 7, 7, 256)    0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 7, 7, 64)     16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 7, 7, 64)     256         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 7, 7, 64)     0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 7, 7, 64)     36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 7, 7, 64)     256         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 7, 7, 64)     0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 7, 7, 256)    16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 7, 7, 256)    1024        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 7, 7, 256)    0           batch_normalization_12[0][0]     \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 7, 7, 256)    0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 7, 7, 64)     16448       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 7, 7, 64)     256         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 7, 7, 64)     0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 7, 7, 64)     36928       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 7, 7, 64)     256         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 7, 7, 64)     0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 7, 7, 256)    16640       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 7, 7, 256)    1024        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 7, 7, 256)    0           batch_normalization_15[0][0]     \n",
            "                                                                 activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 7, 7, 256)    0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 4, 4, 128)    32896       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 4, 4, 128)    512         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 4, 4, 128)    0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 4, 4, 128)    147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 4, 4, 128)    512         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 4, 4, 128)    0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 4, 4, 512)    66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 4, 4, 512)    131584      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 4, 4, 512)    2048        conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 4, 4, 512)    2048        conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 4, 4, 512)    0           batch_normalization_18[0][0]     \n",
            "                                                                 batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 4, 4, 512)    0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 4, 4, 128)    65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 4, 4, 128)    512         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 4, 4, 128)    0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 4, 4, 128)    147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 4, 4, 128)    512         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 4, 4, 128)    0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 4, 4, 512)    66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 4, 4, 512)    2048        conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 4, 4, 512)    0           batch_normalization_22[0][0]     \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 4, 4, 512)    0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 4, 4, 128)    65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 4, 4, 128)    512         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 4, 4, 128)    0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 4, 4, 128)    147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 4, 4, 128)    512         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 4, 4, 128)    0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 4, 4, 512)    66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 4, 4, 512)    2048        conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 4, 4, 512)    0           batch_normalization_25[0][0]     \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 4, 4, 512)    0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 4, 4, 128)    65664       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 4, 4, 128)    512         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 4, 4, 128)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 4, 4, 128)    147584      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 4, 4, 128)    512         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 4, 4, 128)    0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 4, 4, 512)    66048       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 4, 4, 512)    2048        conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 4, 4, 512)    0           batch_normalization_28[0][0]     \n",
            "                                                                 activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 4, 4, 512)    0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 2, 2, 256)    131328      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 2, 2, 256)    1024        conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 2, 2, 256)    0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 2, 2, 256)    590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 2, 2, 256)    1024        conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 2, 2, 256)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 2, 2, 1024)   263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 2, 2, 1024)   525312      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 2, 2, 1024)   4096        conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 2, 2, 1024)   4096        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 2, 2, 1024)   0           batch_normalization_31[0][0]     \n",
            "                                                                 batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 2, 2, 1024)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 2, 2, 256)    262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 2, 2, 256)    1024        conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 2, 2, 256)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 2, 2, 256)    590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 2, 2, 256)    1024        conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 2, 2, 256)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 2, 2, 1024)   263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 2, 2, 1024)   4096        conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 2, 2, 1024)   0           batch_normalization_35[0][0]     \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 2, 2, 1024)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 2, 2, 256)    262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 2, 2, 256)    1024        conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 2, 2, 256)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 2, 2, 256)    590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 2, 2, 256)    1024        conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 2, 2, 256)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 2, 2, 1024)   263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 2, 2, 1024)   4096        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 2, 2, 1024)   0           batch_normalization_38[0][0]     \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 2, 2, 1024)   0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 2, 2, 256)    262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 2, 2, 256)    1024        conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 2, 2, 256)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 2, 2, 256)    590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 2, 2, 256)    1024        conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 2, 2, 256)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 2, 2, 1024)   263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 2, 2, 1024)   4096        conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 2, 2, 1024)   0           batch_normalization_41[0][0]     \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 2, 2, 1024)   0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 2, 2, 256)    262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 2, 2, 256)    1024        conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 2, 2, 256)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 2, 2, 256)    590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 2, 2, 256)    1024        conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 2, 2, 256)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 2, 2, 1024)   263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 2, 2, 1024)   4096        conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 2, 2, 1024)   0           batch_normalization_44[0][0]     \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 2, 2, 1024)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 2, 2, 256)    262400      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 2, 2, 256)    1024        conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 2, 2, 256)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 2, 2, 256)    590080      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 2, 2, 256)    1024        conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 2, 2, 256)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 2, 2, 1024)   263168      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 2, 2, 1024)   4096        conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 2, 2, 1024)   0           batch_normalization_47[0][0]     \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 2, 2, 1024)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 1, 1, 512)    524800      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 1, 1, 512)    2048        conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 1, 1, 512)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 1, 1, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 1, 1, 512)    2048        conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 1, 1, 512)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 1, 1, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 1, 1, 2048)   2099200     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 1, 1, 2048)   8192        conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 1, 1, 2048)   8192        conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 1, 1, 2048)   0           batch_normalization_50[0][0]     \n",
            "                                                                 batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 1, 1, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 1, 1, 256)    524544      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 1, 1, 256)    1024        conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 1, 1, 256)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 1, 1, 256)    590080      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 1, 1, 256)    1024        conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 1, 1, 256)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 1, 1, 2048)   526336      activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 1, 1, 2048)   8192        conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 1, 1, 2048)   0           batch_normalization_54[0][0]     \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 1, 1, 2048)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 1, 1, 256)    524544      activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 1, 1, 256)    1024        conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 1, 1, 256)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 1, 1, 256)    590080      activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 1, 1, 256)    1024        conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 1, 1, 256)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 1, 1, 2048)   526336      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 1, 1, 2048)   8192        conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 1, 1, 2048)   0           batch_normalization_57[0][0]     \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 1, 1, 2048)   0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 1, 1, 2048)   0           activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 2048)         0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           20490       flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 17,966,986\n",
            "Trainable params: 17,915,914\n",
            "Non-trainable params: 51,072\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hi4WfiGnI6e1",
        "colab_type": "text"
      },
      "source": [
        "##CIFAR10 Dataset\n",
        "\n",
        "Simply run the following code block to download and preprocess the CIFAR10 dataset. We also use online data-augmentation to improve the results. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgUU9chm3k4f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b4ac1ec4-175e-4098-f718-a9d8508cc017"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "num_classes = 10\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=True,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "datagen.fit(x_train)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0N36L7P9J1UA",
        "colab_type": "text"
      },
      "source": [
        "##Compile the Model\n",
        "\n",
        "The following block sets the required hyper-parameters, complies the model starts the process of training and at the end saves the trained model. \n",
        "\n",
        "You can use your own hyper-parameters, but these have been tested to work properly.\n",
        "\n",
        "Note that we require you to report the accuracy for models that have been trained for 50 epochs. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf9YlI_LWjfW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "outputId": "b9b5eb67-351c-4d32-aa7a-7b93af1467f7"
      },
      "source": [
        "batch_size = 2048\n",
        "epochs = 50\n",
        "data_augmentation = True\n",
        "learning_rate=0.001\n",
        "\n",
        "opt = keras.optimizers.adam(lr=learning_rate, decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "t1=time()\n",
        "history =model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                    batch_size=batch_size),\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    workers=4)\n",
        "print('Training time is {} s'.format(time()-t1))\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "model_name='resnet'\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "25/25 [==============================] - 56s 2s/step - loss: 2.4174 - acc: 0.2247 - val_loss: 3.9033 - val_acc: 0.1433\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 34s 1s/step - loss: 1.7415 - acc: 0.3571 - val_loss: 2.6634 - val_acc: 0.2653\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 36s 1s/step - loss: 1.5822 - acc: 0.4208 - val_loss: 2.1434 - val_acc: 0.3069\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 35s 1s/step - loss: 1.5333 - acc: 0.4469 - val_loss: 8.2954 - val_acc: 0.1307\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 35s 1s/step - loss: 1.4560 - acc: 0.4704 - val_loss: 1.7729 - val_acc: 0.3924\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 35s 1s/step - loss: 1.3866 - acc: 0.5014 - val_loss: 1.5524 - val_acc: 0.4300\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 35s 1s/step - loss: 1.3607 - acc: 0.5113 - val_loss: 2.1429 - val_acc: 0.3269\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 35s 1s/step - loss: 1.3419 - acc: 0.5207 - val_loss: 2.2416 - val_acc: 0.2859\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 35s 1s/step - loss: 1.3120 - acc: 0.5304 - val_loss: 2.0989 - val_acc: 0.2977\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 34s 1s/step - loss: 1.6539 - acc: 0.4129 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 34s 1s/step - loss: 1.6199 - acc: 0.4190 - val_loss: 14.4375 - val_acc: 0.0991\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 35s 1s/step - loss: 1.4977 - acc: 0.4522 - val_loss: 13.5320 - val_acc: 0.1027\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 34s 1s/step - loss: 1.4489 - acc: 0.4796 - val_loss: 14.1961 - val_acc: 0.1010\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 34s 1s/step - loss: 1.4171 - acc: 0.4920 - val_loss: 13.9264 - val_acc: 0.1042\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 34s 1s/step - loss: 1.3506 - acc: 0.5132 - val_loss: 7.0697 - val_acc: 0.1120\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 34s 1s/step - loss: 1.3245 - acc: 0.5258 - val_loss: 14.1653 - val_acc: 0.1000\n",
            "Epoch 17/50\n",
            " 9/25 [=========>....................] - ETA: 22s - loss: 1.2887 - acc: 0.5323"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuZ9pWM3KmsW",
        "colab_type": "text"
      },
      "source": [
        "##Evaluate the model\n",
        "\n",
        "Simply run the following block of code to plot accuracies on training and validation set during different training epochs and eventually get the **accuracy** of the trained model on the **testing set** of CIFAR10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgWEKQfRdIBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_learningCurve(history,epochs)\n",
        "\n",
        "# Evaluate trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}